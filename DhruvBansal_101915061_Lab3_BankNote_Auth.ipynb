{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a484335c",
   "metadata": {},
   "source": [
    "# Dhruv Bansal-101915061-ENC3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3b9d2",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05ecf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63438fb",
   "metadata": {},
   "source": [
    "## About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d100f83",
   "metadata": {},
   "source": [
    "The Banknote Dataset involves predicting whether a given banknote is authentic given a number of measures taken from a photograph.\n",
    "\n",
    "It is a binary (2-class) classification problem.There are 1,372 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "Variance of Wavelet Transformed image \n",
    "\n",
    "Skewness of Wavelet Transformed image \n",
    "\n",
    "Kurtosis of Wavelet Transformed image \n",
    "\n",
    "Entropy of image \n",
    "\n",
    "Output = 0 for authentic, 1 for inauthentic\n",
    "\n",
    "the dataset has no catagorical data, no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f8f5d",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f340a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data_banknote_authentication.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d433b",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68247ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ed7c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84546   3.4826   -3.6307   -1.3961  ]\n",
      " [ 1.105     7.4432    0.41099  -3.0332  ]\n",
      " [ 5.2012    0.32694   0.17965   1.1797  ]\n",
      " ...\n",
      " [-2.5919   -1.0553    3.8949    0.77757 ]\n",
      " [-1.3274    9.498     2.4408   -5.2689  ]\n",
      " [-0.11716   0.60422  -0.38587  -0.059065]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad23f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1\n",
      " 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0\n",
      " 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0\n",
      " 0 1 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d52058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.3876   -7.7267   11.9655   -1.4543 ]\n",
      " [  1.4501    3.6067   -4.0557   -1.5966 ]\n",
      " [ -4.0173   -8.3123   12.4547   -1.4375 ]\n",
      " ...\n",
      " [ -0.24037  -1.7837    2.135     1.2418 ]\n",
      " [ -2.7611  -10.5099    9.0239   -1.9547 ]\n",
      " [  2.2034    5.9947    0.53009   0.84998]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a263e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0\n",
      " 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
      " 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba255ea2",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34df818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92ae0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15137339  0.24420079 -1.15721408 -0.08705409]\n",
      " [ 0.24308739  0.93695806 -0.1979713  -0.87578768]\n",
      " [ 1.69056708 -0.30776265 -0.25287685  1.15393301]\n",
      " ...\n",
      " [-1.06329113 -0.54953329  0.62888963  0.96019198]\n",
      " [-0.61645307  1.29636765  0.28377782 -1.952919  ]\n",
      " [-0.18878893 -0.25926299 -0.3870957   0.55711207]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1e78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.69784005 -1.71644255  2.54434203 -0.1150941 ]\n",
      " [ 0.36503584  0.2659074  -1.25808233 -0.18365239]\n",
      " [-1.56698664 -1.81887113  2.66044732 -0.10700007]\n",
      " ...\n",
      " [-0.23232782 -0.67693933  0.21120015  1.18385199]\n",
      " [-1.12308156 -2.20325818  1.84619136 -0.35618034]\n",
      " [ 0.63123047  0.68359773 -0.16970445  0.99507818]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f11f2",
   "metadata": {},
   "source": [
    "## Training the Decision Tree Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4f2549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08b86",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958fd49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489d02c",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fd4057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[300   7]\n",
      " [  2 240]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9836065573770492"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadaffab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
